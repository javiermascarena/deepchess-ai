{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_functions import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PROCESSING**\n",
    "\n",
    "- Importing the pgn data\n",
    "- Transforming the data to sparce tensors \n",
    "- Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PERCENT = 0.25\n",
    "\n",
    "# Load pgn paths\n",
    "pgns = import_data(1)\n",
    "\n",
    "# Convert pgns to tensors\n",
    "board_tensors, next_moves = parse_pgn_to_tensors(pgns)\n",
    "\n",
    "# Converting the dataset into a custom pytorch one\n",
    "dataset = ChessDataset(board_tensors, next_moves)\n",
    "\n",
    "# Splitting the data into train and test\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [1-TEST_PERCENT, TEST_PERCENT])\n",
    "\n",
    "print(len(test_data))  # Number of states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK DESIGN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Whether to do the operations on the cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PieceToMoveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Takes as input a tensor of 14 channels (8x8 board)\n",
    "        self.conv1 = nn.Conv2d(14, 6, 3)  # 6 filters, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # Max pooling with 2x2 window\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)  # 16 filters, 3x3 kernel\n",
    "        \n",
    "        # If starting with 8x8, after two pool layers it becomes 2x2.\n",
    "        # Output from conv2 will be (16 channels, 2x2 feature maps), flattened to 16 * 2 * 2 = 64\n",
    "        self.fc1 = nn.Linear(16 * 2 * 2, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Predicts the tile to move the piece from (64 possible tiles on the board)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Apply first conv + pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Apply second conv + pooling\n",
    "        x = torch.flatten(x, BATCH_SIZE)  # Flatten all dimensions except batch size\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer 1\n",
    "        x = F.relu(self.fc2(x))  # Fully connected layer 2\n",
    "        x = self.fc3(x)          # Output layer (no activation, logits for classification)\n",
    "        return x\n",
    "\n",
    "piece_to_move_net = PieceToMoveNet()\n",
    "# Move the network to gpu / cpu befor initializing the optimizer\n",
    "piece_to_move_net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(piece_to_move_net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING LOOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(board: chess.Board, outputs: np.arry, labels: np.array) -> np.array:\n",
    "    \"\"\"Creates mask with legal moves from the current board state\"\"\"\n",
    "\n",
    "    mask = np.zeros((8,8)) # 8x8 mask for the chessboard\n",
    "\n",
    "    # Obtaining legal moves from the board\n",
    "    legal_moves = list(board.legal_moves)\n",
    "\n",
    "    # Indicating with 1s the valid squares\n",
    "    for move in legal_moves:\n",
    "        to_square = move.to_square\n",
    "        to_row, to_col = divmod(to_square, 8)\n",
    "        mask[to_row, to_col] = 1 # A valid square\n",
    "\n",
    "    # Reshaping mask to match output and labels\n",
    "    move_mask = mask.flatten() # Converts 8*8 2D array to a 1D array with 64 elements\n",
    "\n",
    "    masked_outputs = outputs * move_mask\n",
    "    masked_labels = labels * move_mask\n",
    "\n",
    "    return masked_outputs, masked_labels\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "train_data, validation_data = torch.utils.data.random_split(train_data, [1-TEST_PERCENT, TEST_PERCENT])\n",
    "\n",
    "training_loader = torch.utils.data.dataLoader(train_data, BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "validation_loader = torch.utils.data.dataLoader(validation_data, BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index: int, tb_writer): \n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = piece_to_move_net(inputs)\n",
    "\n",
    "        masked_outputs, masked_labels =        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999: \n",
    "            last_loss = running_loss / 1000\n",
    "            print(f\" batch {i + 1}, loss: {last_loss}\")\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "    print(f\"EPOCH {epoch + 1}: \")\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch, writer)\n",
    "\n",
    "    model.train(False)\n",
    "    running_vloss = 0.0\n",
    "    for i, v_data in enumerate(validation_loader):\n",
    "        vinputs = v_data[0]\n",
    "        vlabels = v_data[1]\n",
    "\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(f\"LOSS train {avg_loss}, valid {avg_vloss}\")\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation Loss\", {\n",
    "        \"Training\": avg_loss, \"Validation\": avg_vloss}, \n",
    "        epoch + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_loss\n",
    "        model_path = f\"model_{timestamp}_{epoch}\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
