{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(aux_functions)\n",
    "from aux_functions import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset, SubsetRandomSampler\n",
    "# For masking\n",
    "from torch.masked import masked_tensor, as_masked_tensor\n",
    "\n",
    "import numpy as np\n",
    "import chess\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PROCESSING**\n",
    "\n",
    "- Importing the pgn data\n",
    "- Transforming the data to sparce tensors \n",
    "- Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "[414, 235, 1355, 1009, 437, 1064, 2105, 260, 2175, 81, 291, 79, 728, 2653, 2508, 1510, 2518, 2965, 2428, 1621, 2124, 763, 1293, 797, 1454, 1299, 443, 686, 967, 2616, 231, 283, 2045, 49, 2573, 717, 2412, 2931, 1205, 376, 678, 3326, 2258, 986, 1175, 861, 929, 1622, 3254, 3260, 3038, 408, 705, 1465, 949, 1752, 3331, 3113, 222, 365, 879, 128, 3065, 1309, 1241, 3233, 284, 2849, 2422, 2786, 1131, 1511, 92, 1568, 114, 2332, 2917, 1498, 1287, 1329, 126, 2037, 1326, 1383, 995, 1641, 3007, 3150, 293, 671, 2797, 206, 974, 3096, 2249, 229, 2462, 4, 2707, 1108, 35, 1747, 3098, 3055, 442, 1006, 2830, 2053, 393, 2667, 2633, 883, 1056, 1983, 1274, 1399, 3317, 100, 2969, 1744, 3337, 62, 1575, 2861, 1433, 715, 719, 2141, 2795, 2809, 446, 2584, 2959, 2831, 470, 1093, 2034, 381, 2264, 1448, 683, 1388, 1432, 1123, 1047, 941, 2257, 976, 959, 699, 790, 767, 2064, 2994, 2568, 2367, 833, 3168, 1400, 1325, 2240, 277, 2949, 1449, 2513, 3061, 1336, 1401, 3335, 290, 3339, 1367, 2817, 3114, 1415, 787, 2087, 2304, 464, 1535, 3207, 1555, 321, 2790, 2503, 1856, 1438, 2145, 3262, 2638, 1833, 157, 378, 2761, 1734, 1345, 1530, 2149, 2868, 113, 997, 1424, 2737, 2368, 2280, 1995, 1803, 1871, 2538, 2449, 1593, 546, 74, 3177, 2488, 3199, 1944, 3100, 2706, 1248, 2152, 1888, 2162, 880, 707, 118, 2838, 1370, 835, 3248, 1091, 1922, 178, 2765, 1642, 2050, 2101, 423, 711, 1363, 2564, 263, 1852, 2260, 2203, 730, 2711, 588, 354, 1285, 193, 5, 2741, 2605, 2603, 3013, 1343, 2825, 1038, 3330, 687, 2836, 2120, 108, 742, 803, 869, 1114, 3243, 2665, 2591, 1687, 110, 2792, 2918, 649, 1557, 3261, 1753, 794, 1919, 1070, 800, 1881, 496, 3156, 2068, 651, 1273, 1036, 481, 2522, 502, 2007, 574, 3304, 1928, 1238, 1889, 999, 3151, 2163, 2341, 1663, 2566, 2423, 1897, 150, 1083, 2853, 85, 799, 0, 2006, 3003, 3044, 2061, 227, 3223, 2799, 1969, 2743, 1201, 2912, 2110, 1397, 690, 702, 1855, 1138, 2020, 2271, 2179, 1001, 2421, 1910, 1573, 2338, 3062, 780, 192, 981, 2455, 3173, 2608, 2207, 1574, 3221, 238, 796, 2171, 335, 1647, 2130, 1786, 1422, 3026, 2217, 2215, 3220, 2880, 1271, 2794, 29, 2926, 266, 2858, 1916, 1313, 511, 3237, 975, 779, 2035, 3028, 724, 419, 2783, 920, 2443, 2371, 2673, 26, 1321, 737, 1227, 1194, 2049, 3291, 1368, 138, 2238, 1467, 115, 1525, 1451, 1289, 1954, 2916, 3107, 2898, 1514, 3180, 636, 2901, 83, 1223, 862, 1381, 647, 181, 2405, 1595, 1492, 2782, 899, 2637, 1931, 1661, 521, 3299, 367, 582, 3258, 2299, 1080, 1740, 627, 1968, 1067, 1706, 2977, 2553, 215, 3198, 2075, 1339, 71, 3121, 1119, 125, 2889, 120, 1214, 1215, 2279, 2195, 1746, 923, 59, 2402, 3023, 3300, 3006, 2450, 3120, 1317, 1409, 508, 205, 360, 2404, 898, 514, 40, 1104, 2013, 874, 2697, 3372, 830, 3205, 793, 352, 258, 572, 94, 2363, 1075, 372, 1820, 2316, 1666, 1469, 1304, 2625, 762, 296, 3285, 1173, 1133, 2177, 2407, 1630, 2139, 1042, 2081, 925, 2791, 2903, 847, 48, 2738, 2025, 3050, 105, 3249, 6, 1022, 2796, 479, 3086, 1658, 1960, 3090, 3174, 658, 2362, 95, 1659, 2546, 2659, 834, 628, 1233, 872, 480, 1826, 1506, 1633, 1802, 888, 3316, 622, 1324, 2694, 1775, 54, 2542, 449, 2624, 2144, 2733, 530, 1645, 2281, 2106, 1946, 854, 189, 1139, 812, 2798, 2690, 2302, 23, 494, 129, 2708, 63, 2689, 3200, 1503, 2235, 2243, 1305, 3025, 390, 1867, 2702, 727, 831, 829, 2159, 2684, 2172, 2283, 1668, 1731, 2397, 2248, 668, 2382, 1809, 2491, 2331, 435, 1695, 497, 2430, 2224, 2474, 1290, 384, 2014, 2501, 666, 695, 2976, 532, 820, 1189, 1117, 3166, 3141, 2067, 528, 1991, 659, 438, 341, 1724, 643, 1887, 1394, 1033, 2285, 2041, 816, 3265, 757, 3158, 2442, 1721, 2940, 1500, 300, 3184, 3381, 478, 2160, 1177, 602, 2655, 2364, 663, 662, 2319, 1134, 2307, 2343, 561, 950, 255, 3368, 2490, 3187, 2744, 556, 1517, 3183, 1008, 805, 2228, 2692, 3280, 3364, 1335, 3149, 1678, 597, 3085, 2498, 1172, 3338, 3127, 3109, 1442, 1589, 86, 564, 2517, 1027, 1804, 2259, 1697, 765, 2756, 585, 701, 1, 73, 3060, 1257, 1140, 3320, 1628, 3349, 2696, 2512, 2340, 1236, 823, 3247, 1801, 633, 450, 2077, 1069, 2748, 444, 2387, 2929, 2878, 452, 259, 679, 2908, 3363, 2146, 3169, 1736, 2389, 1078, 2718, 1974, 2329, 2122, 1213, 1518, 2759, 782, 1010, 1272, 422, 786, 198, 361, 1581, 2740, 581, 3269, 1196, 3345, 540, 1722, 462, 1031, 2473, 1037, 2310, 2230, 1452, 3322, 2444, 1102, 1406, 2620, 858, 817, 2070, 1224, 388, 2295, 2845, 1540, 1340, 463, 2859, 2820, 2439, 1959, 2424, 2005, 1703, 1089, 1605, 466, 1497, 3144, 1016, 571, 2828, 2826, 379, 915, 548, 2263, 485, 1167, 2214, 1839, 1636, 1461, 3088, 2985, 1726, 1192, 2127, 2019, 3352, 2857, 1019, 241, 980, 1463, 1456, 1615, 3070, 469, 2587, 3163, 1551, 2670, 1352, 1404, 1225, 1411, 2072, 554, 945, 1719, 1836, 2935, 1866, 304, 1296, 697, 673, 2115, 534, 2533, 2972, 1283, 2471, 2979, 1655, 234, 684, 2938, 3235, 3056, 1979, 1773, 130, 2209, 399, 3080, 2672, 3039, 338, 116, 1015, 2769, 2675, 1584, 2022, 340, 1254, 604, 2119, 2531, 568, 1987, 1212, 1264, 2018, 420, 2425, 610, 938, 3073, 505, 1592, 1891, 1681, 2393, 3234, 1094, 2652, 3024, 844, 2891, 303, 2647, 2398, 2763, 1239, 219, 2246, 1932, 166, 2735, 3239, 1745, 620, 2446, 1696, 380, 2816, 3042, 1121, 89, 2928, 1582, 2470, 216, 209, 2180, 1670, 2495, 982, 1873, 2460, 2520, 1446, 909, 1561, 832, 2016, 1314, 865, 2704, 897, 1798, 1197, 2919, 3045, 1842, 2457, 1132, 1813, 164, 594, 2255, 407, 2958, 2993, 3276, 3138, 3332, 1694, 172, 249, 183, 1905, 127, 1886, 3315, 2385, 3351, 605, 1649, 2071, 2987, 553, 2847, 1939, 1755, 3232, 2944, 1652, 1702, 2274, 21, 896, 2618, 1328, 2864, 2899, 1918, 1738, 3270, 842, 2688, 3328, 1311, 2126, 398, 808, 1603, 579, 212, 1816, 722, 2210, 3348, 3307, 1484, 1185, 906, 1493, 2459, 2932, 638, 2353, 2955, 12, 2651, 477, 2088, 2166, 887, 1827, 3192, 2896, 208, 1436, 3103, 1966, 507, 1221, 250, 1435, 838, 1524, 1505, 642, 1921, 2681, 1412, 2082, 1164, 603, 652, 1792, 2877, 621, 2960, 1964, 1504, 2167, 3240, 483, 537, 1757, 3196, 968, 1758, 1437, 3135, 2686, 3095, 676, 1077, 491, 3217, 11, 3146, 1149, 1112, 1818, 2900, 2187, 3301, 349, 18, 783, 436, 2392, 2663, 2881, 1228, 3010, 694, 7, 3370, 1560, 1103, 746, 934, 3289, 2266, 1784, 275, 2749, 343, 542, 2282, 3142, 1405, 1623, 370, 2586, 311, 1439, 357, 2888, 1426, 1539, 2311, 256, 1536, 947, 630, 1998, 1512, 1858, 640, 1190, 2805, 674, 2885, 721, 168, 392, 2360, 187, 1318, 1848, 580, 289, 1322, 596, 1198, 2284, 2504, 140, 50, 1519, 424, 2677, 1090, 1685, 1430, 525, 1612, 2669, 1136, 211, 2855, 165, 3188, 2722, 2352, 1030, 706, 156, 2909, 3030, 2876, 1768, 3185, 2256, 1817, 91, 1414, 1679, 1546, 774, 754, 1545, 1390, 2227, 2572, 639, 1307, 547, 268, 3082, 1578, 270, 123, 315, 484, 1346, 1220, 2793, 2410, 2322, 592, 2361, 245, 893, 1377, 2911, 2860, 1458, 455, 2556, 3342, 2465, 791, 856, 2760, 1677, 2807, 1182, 2497, 1606, 1028, 611, 242, 1181, 3091, 1174, 966, 1587, 415, 2923, 329, 3303, 1499, 1413, 617, 2514, 1914, 1260, 2479, 2357, 1298, 1877, 2551, 641, 2001, 244, 2438, 2986, 2234, 1129, 1608, 90, 1815, 1005, 1682, 3153, 2770, 2391, 1058, 1654, 428, 2927, 988, 2244, 2485, 618, 2674, 1614, 942, 958, 1478, 1071, 1926, 2326, 1186, 41, 2950, 713, 1883, 2108, 2806, 3182, 849, 905, 2775, 3134, 1391, 2486, 3078, 855, 2445, 1294, 2189, 2038, 201, 1098, 710, 3216, 3122, 1794, 1043, 1419, 8, 2480, 1532, 1594, 3273, 1126, 121, 644, 2121, 836, 1920, 3170, 2821, 1885, 3077, 1844, 2597, 1348, 2930, 1051, 3057, 2002, 784, 770, 769, 3019, 619, 3047, 2656, 1473, 33, 308, 1332, 1978, 1007, 3041, 332, 810, 1812, 153, 519, 93, 853, 886, 171, 2867, 1230, 1124, 2839, 2649, 1086, 328, 1674, 1199, 1195, 1060, 1002, 2784, 2593, 3257, 1814, 598, 1249, 2636, 2117, 1710, 1543, 2017, 2140, 2048, 2487, 3005, 1947, 2823, 682, 2990, 1997, 279, 1846, 1548, 204, 1331, 747, 2639, 3112, 1643, 1558, 1269, 2231, 1847, 1763, 859, 601, 3020, 826, 1534, 1143, 1896, 2309, 2724, 2345, 1680, 1231, 2602, 72, 1971, 1088, 1788, 1723, 522, 3167, 3309, 1369, 1996, 1247, 751, 2024, 2043, 3227, 2245, 2511, 903, 1531, 660, 1875, 1113, 545, 1849, 2968, 2946, 3022, 44, 112, 400, 1748, 1901, 1577, 1495, 3283, 1952, 2808, 1222, 2730, 3323, 3319, 1992, 2289, 3058, 623, 2532, 3308, 2118, 133, 2074, 102, 667, 471, 1443, 2601, 2489, 184, 2519, 3347, 1250, 1474, 1163, 889, 1904, 589, 2003, 1835, 2524, 1347, 612, 3037, 570, 151, 3129, 3350, 1356, 3087, 334, 1878, 64, 2612, 3253, 1320, 2031, 441, 3105, 3115, 2301, 185, 2496, 3094, 47, 1772, 1382, 3357, 2493, 88, 3252, 1750, 573, 3246, 281, 635, 1384, 2057, 1529, 1045, 2771, 1930, 2804, 3292, 265, 109, 3313, 3251, 2206, 1973, 2313, 2543, 2176, 373, 996, 292, 2713, 517, 3324, 1242, 2196, 1785, 2335, 2194, 1263, 1183, 2237, 1559, 1202, 2296, 2716, 1771, 2153, 3213, 1154, 1880, 2824, 2865, 821, 586, 80, 1488, 3191, 857, 3376, 1796, 1542, 1756, 509, 3101, 1243, 2337, 1764, 3089, 410, 39, 2330, 2609, 257, 919, 2056, 2635, 3354, 656, 1934, 2646, 2286, 2535, 2787, 1462, 2200, 3297, 2600, 3011, 1158, 374, 492, 2613, 1105, 569, 3356, 3190, 2592, 2178, 13, 595, 809, 14, 1207, 2844, 1470, 3255, 1278, 804, 900, 2942, 3033, 1638, 1629, 1845, 918, 1127, 3333, 1585, 188, 2441, 1020, 30, 3362, 225, 1166, 2948, 1170, 1541, 2135, 2317, 1993, 2561, 3084, 560, 529, 213, 1913, 3128, 3035, 1279, 1000, 36, 1156, 371, 2028, 2507, 1725, 2400, 2347, 2112, 1076, 2712, 1829, 467, 2190, 2879, 2666, 1787, 1619, 2358, 2009, 2150, 324, 1712, 2774, 3126, 700, 819, 1011, 1096, 421, 901, 761, 2643, 2634, 1571, 1936, 369, 96, 2606, 1893, 1565, 2395, 2789, 3334, 1762, 445, 3092, 318, 846, 1097, 549, 1733, 2023, 418, 2978, 273, 2872, 877, 3202, 412, 3195, 827, 2086, 1057, 131, 3225, 3310, 788, 1689, 218, 2435, 224, 1471, 1657, 624, 2419, 2089, 2500, 646, 262, 1556, 2842, 1970, 3004, 2988, 2272, 495, 356, 401, 3178, 3374, 2750, 1403, 2550, 176, 1791, 145, 1950, 37, 523, 382, 1065, 1150, 1933, 2373, 2526, 1316, 1523, 1253, 175, 2660, 1945, 1044, 243, 1165, 1082, 1387, 2569, 425, 3256, 1783, 501, 1599, 331, 161, 362, 1300, 921, 1728, 1553, 2211, 2472, 267, 2945, 2275, 655, 2411, 3139, 2776, 931, 3228, 2574, 2662, 1927, 1427, 3355, 868, 3081, 1282, 1562, 1912, 1393, 1537, 2137, 2802, 894, 1188, 1691, 1607, 2342, 773, 386, 2902, 2915, 1683, 3108, 248, 2406, 3076, 197, 2156, 1665, 973, 518, 2218, 2641, 2481, 316, 347, 1074, 1502, 2679, 1963, 297, 2113, 908, 802, 389, 3293, 1203, 1402, 2456, 1344, 2454, 1507, 2952, 965, 1860, 1554, 1152, 403, 2351, 1380, 27, 1770, 233, 190, 3099, 3136, 1509, 2980, 2063, 2621, 144, 2590, 498, 933, 1048, 927, 2850, 972, 475, 1361, 317, 426, 2133, 1211, 56, 1705, 38, 1145, 1859, 2974, 1464, 306, 881, 1776, 239, 448, 1717, 2094, 269, 2314, 2223, 1245, 1032, 1962, 3241, 1444, 2710, 696, 1206, 3272, 186, 634, 2381, 2866, 2107, 1162, 2714, 1237, 2212, 2109, 1874, 1800, 648, 1244, 1395, 2727, 1876, 3305, 34, 3336, 2982, 1735, 2085, 3179, 2293, 1781, 2452, 3008, 2267, 1226, 998, 3130, 2680, 1389, 1549, 504, 298, 1729, 2615, 3340, 1870, 1385, 427, 2241, 1365, 1204, 1868, 2193, 2970, 2871, 2440, 1739, 2339, 2000, 1479, 119, 203, 952, 2719, 2197, 629, 1994, 951, 2492, 1806, 1256, 2093, 261, 1081, 1341, 3380, 1455, 3193, 2966, 1334, 2379, 677, 814, 240, 1410, 2510, 194, 254, 2102, 3208, 3093, 2736, 845, 3377, 1564, 2396, 2562, 2142, 562, 2732, 755, 375, 1200, 689, 274, 3379, 1161, 2394, 1778, 3290, 302, 2614, 2494, 1417, 2065, 2567, 593, 813, 312, 405, 943, 734, 1972, 2910, 2409, 1440, 1486, 2188, 3137, 1379, 3119, 2715, 3160, 818, 1251, 971, 199, 1598, 3110, 1583, 3054, 3244, 1648, 3155, 778, 1106, 2922, 2463, 1235, 987, 2219, 510, 503, 1567, 1713, 489, 223, 3036, 2202, 625, 567, 3124, 961, 2701, 1808, 1650, 2432, 2557, 327, 252, 77, 1637, 2907, 1333, 1949, 2906, 1487, 87, 3302, 1496, 3157, 1988, 3373, 3219, 3002, 653, 104, 155, 2216, 1720, 1841, 1084, 637, 355, 3294, 2983, 1751, 714, 1692, 1447, 2033, 2873, 1906, 922, 807, 1366, 1782, 2242, 3067, 2205, 416, 2619, 2971, 789, 680, 174, 68, 2116, 1823, 60, 1258, 870, 2962, 246, 2015, 170, 3052, 348, 2788, 98, 1398, 2552, 2303, 251, 1407, 940, 2540, 1281, 2883, 2011, 979, 924, 2288, 1632, 2747, 1671, 2992, 1828, 3346, 795, 775, 447, 2664, 1900, 2981, 1759, 2728, 1899, 760, 1327, 608, 613, 217, 937, 3097, 3014, 2261, 2581, 17, 1766, 111, 913, 305, 2897, 1547, 1216, 2333, 985, 1441, 141, 1323, 32, 143, 1700, 541, 2098, 2627, 2174, 1276, 840, 2039, 2298, 1476, 2466, 2170, 3365, 31, 3189, 2386, 1769, 3329, 1291, 202, 2604, 3282, 2370, 2458, 2699, 708, 2164, 2964, 1662, 1869, 2328, 1653, 1137, 1209, 2525, 2273, 2226, 2623, 738, 2780, 1805, 322, 57, 278, 2811, 1831, 2051, 1286, 2408, 299, 607, 2645, 103, 3375, 2575, 2943, 2161, 2278, 2004, 2377, 3186, 1981, 2420, 2469, 977, 1151, 2374, 1109, 1308, 536, 1790, 2703, 693, 2506, 1135, 160, 55, 2058, 2073, 1265, 3366, 2698, 939, 2390, 914, 101, 20, 1942, 645, 891, 3051, 288, 2012, 935, 851, 2822, 1171, 1990, 1989, 2521, 2165, 1596, 2453, 122, 2434, 2268, 1570, 180, 1693, 1902, 1386, 2173, 2198, 1627, 1908, 2937, 506, 3, 1576, 3029, 863, 1040, 792, 954, 2729, 1364, 962, 309, 1984, 2059, 1148, 2995, 1099, 1765, 402, 173, 58, 3209, 2963, 1741, 3040, 2325, 2598, 928, 2251, 2843, 3268, 169, 2100, 2837, 1837, 2785, 3059, 2192, 2300, 3165, 2431, 2042, 1358, 2676, 2290, 2467, 1861, 2626, 716, 383, 1085, 2848, 413, 3145, 1374, 2097, 1445, 1618, 2813, 1911, 3116, 3281, 3222, 2233, 1457, 1302, 2306, 723, 1797, 2182, 2157, 2052, 1951, 433, 1092, 2447, 1023, 1141, 1610, 712, 3162, 1879, 2545, 377, 1193, 1854, 3321, 1580, 917, 1843, 2835, 177, 2893, 313, 1810, 1408, 2800, 1631, 2375, 2383, 196, 2476, 1591, 2415, 815, 1046, 353, 2292, 1999, 1982, 843, 2695, 1420, 3312, 142, 969, 1626, 3001, 2047, 9, 301, 1714, 1303, 76, 1059, 3369, 1012, 1354, 1466, 16, 768, 1675, 1777, 551, 616, 3066, 1280, 1115, 1634, 490, 226, 3152, 1651, 781, 2869, 2348, 1516, 1915, 3147, 806, 824, 672, 2734, 650, 465, 2709, 1246, 1351, 1315, 563, 2577, 2477, 1485, 1850, 2854, 404, 191, 1359, 1985, 1604, 895, 1353, 339, 1477, 990, 2247, 910, 2380, 2754, 878, 2642, 1644, 2726, 1004, 319, 2478, 1483, 2095, 731, 732, 1538, 2482, 237, 429, 70, 2658, 1144, 3009, 468, 685, 124, 3360, 748, 15, 453, 1853, 1360, 2607, 1822, 2725, 1660, 1701, 726, 2555, 1482, 2953, 3361, 2232, 3172, 1882, 956, 2904, 2818, 2921, 3074, 2417, 735, 1130, 1295, 1521, 1396, 159, 609, 3259, 3131, 99, 1563, 1862, 2044, 221, 512, 3306, 2815, 2851, 1673, 871, 2384, 2148, 1068, 3181, 575, 3210, 1625, 1372, 162, 2700, 739, 3245, 2327, 2104, 207, 615, 1475, 1948, 3250, 957, 3236, 42, 2947, 3083, 2829, 2403, 2571, 1063, 2693, 675, 2516, 460, 487, 1749, 2599, 670, 688, 3275, 2, 2132, 2451, 2611, 134, 1072]\n"
     ]
    }
   ],
   "source": [
    "TEST_PERCENT = 0.25\n",
    "\n",
    "# Load pgn paths\n",
    "pgns = import_data(5)\n",
    "\n",
    "# Convert pgns to tensors\n",
    "board_tensors, next_moves = parse_pgn_to_tensors(pgns)\n",
    "\n",
    "# Converting the dataset into a custom pytorch one\n",
    "dataset = ChessDataset(board_tensors, next_moves)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# Splitting the data into train and test\n",
    "train_dataset, test_data = torch.utils.data.random_split(dataset, [1-TEST_PERCENT, TEST_PERCENT])\n",
    "\n",
    "print(len(test_data))  # Number of states\n",
    "print(train_dataset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK DESIGN**\n",
    "- 2 Convolutional layers\n",
    "- 2 Fully connected hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to do the operations on the cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PieceToMoveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Takes as input a tensor of 14 channels (8x8 board)\n",
    "        self.conv1 = nn.Conv2d(14, 6, 3)  # 6 filters, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # Max pooling with 2x2 window\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)  # 16 filters, 3x3 kernel\n",
    "\n",
    "        # Using droput to reduce overfitting\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        # Using batch normalization to make training faster and more stable\n",
    "        self.bn1 = nn.BatchNorm1d(120)  # For the 1st layer\n",
    "        self.bn2 = nn.BatchNorm1d(84)   # For the 2nd layer\n",
    "        \n",
    "        # Output from conv2 will be (16 channels, 1x1 feature maps)\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Predicts the tile to move the piece from (64 possible tiles on the board)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Apply first conv + pooling\n",
    "        x = F.relu(self.conv2(x))             # Apply second conv to get (16 x 1 x 1)\n",
    "        x = torch.flatten(x, 1)               # Flatten all dimensions except batch size\n",
    "        x = F.relu(self.bn1(self.fc1(x)))     # Fully connected layer 1 and batch normalization\n",
    "        x = self.dropout(x)                   # Dropout of some first layer neurons\n",
    "        x = F.relu(self.bn2(self.fc2(x)))     # Fully connected layer 2\n",
    "        x = self.fc3(x)                       # Output layer (no activation, logits for classification)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING LOOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "Epoch: 1 Train Loss: 4.079975537955761, Valid Loss: 3.9653835147619247 | Train Acc: 0.04189255791030064, Valid Acc: 0.09448818897637795\n",
      "Epoch: 2 Train Loss: 3.5440512634813786, Valid Loss: 2.8456623554229736 | Train Acc: 0.20601281419418432, Valid Acc: 0.265748031496063\n",
      "Epoch: 3 Train Loss: 2.1823711451143026, Valid Loss: 1.8272282183170319 | Train Acc: 0.26761951700345, Valid Acc: 0.297244094488189\n",
      "Epoch: 4 Train Loss: 1.7911275923252106, Valid Loss: 1.7463356256484985 | Train Acc: 0.2932479053721045, Valid Acc: 0.31299212598425197\n",
      "Epoch: 5 Train Loss: 1.7417344618588686, Valid Loss: 1.7153668031096458 | Train Acc: 0.29620502710694924, Valid Acc: 0.32086614173228345\n",
      "Epoch: 6 Train Loss: 1.7144139222800732, Valid Loss: 1.7047735154628754 | Train Acc: 0.3035978314440611, Valid Acc: 0.3090551181102362\n",
      "Epoch: 7 Train Loss: 1.6950831431895494, Valid Loss: 1.6889970526099205 | Train Acc: 0.30655495317890585, Valid Acc: 0.30118110236220474\n",
      "Epoch: 8 Train Loss: 1.6770307272672653, Valid Loss: 1.677385799586773 | Train Acc: 0.31789058649581076, Valid Acc: 0.28937007874015747\n",
      "Epoch: 9 Train Loss: 1.662274856120348, Valid Loss: 1.665526606142521 | Train Acc: 0.3164120256283884, Valid Acc: 0.3248031496062992\n",
      "Epoch: 10 Train Loss: 1.6465297564864159, Valid Loss: 1.6648601740598679 | Train Acc: 0.32577624445539677, Valid Acc: 0.30118110236220474\n",
      "Epoch: 11 Train Loss: 1.6355064008384943, Valid Loss: 1.681054450571537 | Train Acc: 0.34598324297683586, Valid Acc: 0.30118110236220474\n",
      "Epoch: 12 Train Loss: 1.623785126954317, Valid Loss: 1.6509917229413986 | Train Acc: 0.3361261705273534, Valid Acc: 0.31496062992125984\n",
      "Epoch: 13 Train Loss: 1.614685334265232, Valid Loss: 1.6513543277978897 | Train Acc: 0.34746180384425823, Valid Acc: 0.33267716535433073\n",
      "Epoch: 14 Train Loss: 1.5996086243540049, Valid Loss: 1.649799607694149 | Train Acc: 0.34696895022178414, Valid Acc: 0.3188976377952756\n",
      "Epoch: 15 Train Loss: 1.5870667956769466, Valid Loss: 1.6378892809152603 | Train Acc: 0.3445046821094135, Valid Acc: 0.31496062992125984\n",
      "Epoch: 16 Train Loss: 1.5814059395343065, Valid Loss: 1.6448836028575897 | Train Acc: 0.3578117299162149, Valid Acc: 0.3188976377952756\n",
      "Epoch: 17 Train Loss: 1.5712910275906324, Valid Loss: 1.6351897791028023 | Train Acc: 0.35879743716116314, Valid Acc: 0.3169291338582677\n",
      "Epoch: 18 Train Loss: 1.5585958044975996, Valid Loss: 1.6432486176490784 | Train Acc: 0.3721044849679645, Valid Acc: 0.328740157480315\n",
      "Epoch: 19 Train Loss: 1.5519018545746803, Valid Loss: 1.6295348703861237 | Train Acc: 0.3627402661409561, Valid Acc: 0.3090551181102362\n",
      "Epoch: 20 Train Loss: 1.5452462267130613, Valid Loss: 1.629066377878189 | Train Acc: 0.36717594874322323, Valid Acc: 0.3188976377952756\n",
      "Epoch: 21 Train Loss: 1.5375366248190403, Valid Loss: 1.6347080990672112 | Train Acc: 0.3765401675702316, Valid Acc: 0.3188976377952756\n",
      "Epoch: 22 Train Loss: 1.529157418757677, Valid Loss: 1.6262296736240387 | Train Acc: 0.3735830458353869, Valid Acc: 0.3090551181102362\n",
      "Epoch: 23 Train Loss: 1.5171995740383863, Valid Loss: 1.627694457769394 | Train Acc: 0.3868900936421883, Valid Acc: 0.30118110236220474\n",
      "Epoch: 24 Train Loss: 1.5141303800046444, Valid Loss: 1.6258122771978378 | Train Acc: 0.3735830458353869, Valid Acc: 0.33661417322834647\n",
      "Epoch: 25 Train Loss: 1.504492899402976, Valid Loss: 1.6213438138365746 | Train Acc: 0.378018728437654, Valid Acc: 0.3110236220472441\n",
      "Epoch: 26 Train Loss: 1.50009885430336, Valid Loss: 1.6213569790124893 | Train Acc: 0.39034006899950713, Valid Acc: 0.3228346456692913\n",
      "Epoch: 27 Train Loss: 1.4884085562080145, Valid Loss: 1.6418552249670029 | Train Acc: 0.38836865450961067, Valid Acc: 0.3090551181102362\n",
      "Epoch: 28 Train Loss: 1.480509975925088, Valid Loss: 1.621170036494732 | Train Acc: 0.3893543617545589, Valid Acc: 0.30708661417322836\n",
      "Epoch: 29 Train Loss: 1.4735858514904976, Valid Loss: 1.6223142445087433 | Train Acc: 0.3992114342040414, Valid Acc: 0.30708661417322836\n",
      "Epoch: 30 Train Loss: 1.4632369577884674, Valid Loss: 1.6234930083155632 | Train Acc: 0.4051256776737309, Valid Acc: 0.31496062992125984\n",
      "Epoch: 31 Train Loss: 1.460169441998005, Valid Loss: 1.6203919053077698 | Train Acc: 0.3992114342040414, Valid Acc: 0.328740157480315\n",
      "Epoch: 32 Train Loss: 1.453610636293888, Valid Loss: 1.6280335485935211 | Train Acc: 0.4006899950714638, Valid Acc: 0.3090551181102362\n",
      "Epoch: 33 Train Loss: 1.442919434979558, Valid Loss: 1.6247850507497787 | Train Acc: 0.4115327747658945, Valid Acc: 0.31299212598425197\n",
      "Epoch: 34 Train Loss: 1.4349723998457193, Valid Loss: 1.623020738363266 | Train Acc: 0.4075899457861015, Valid Acc: 0.3090551181102362\n",
      "Epoch: 35 Train Loss: 1.4263492412865162, Valid Loss: 1.623635083436966 | Train Acc: 0.4248398225726959, Valid Acc: 0.32086614173228345\n",
      "Epoch: 36 Train Loss: 1.4234985504299402, Valid Loss: 1.618080347776413 | Train Acc: 0.4218827008378512, Valid Acc: 0.3346456692913386\n",
      "Epoch: 37 Train Loss: 1.4095710795372725, Valid Loss: 1.6250599548220634 | Train Acc: 0.4268112370625924, Valid Acc: 0.3248031496062992\n",
      "Epoch: 38 Train Loss: 1.407608775421977, Valid Loss: 1.6290625110268593 | Train Acc: 0.4307540660423854, Valid Acc: 0.3346456692913386\n",
      "Epoch: 39 Train Loss: 1.3986808117479086, Valid Loss: 1.6323566362261772 | Train Acc: 0.4297683587974372, Valid Acc: 0.33267716535433073\n",
      "Epoch: 40 Train Loss: 1.402424487285316, Valid Loss: 1.6420110538601875 | Train Acc: 0.4366683095120749, Valid Acc: 0.3110236220472441\n",
      "Epoch: 41 Train Loss: 1.3893500305712223, Valid Loss: 1.6184548884630203 | Train Acc: 0.4415968457368162, Valid Acc: 0.31496062992125984\n",
      "Epoch: 42 Train Loss: 1.381465246900916, Valid Loss: 1.625997968018055 | Train Acc: 0.4346968950221784, Valid Acc: 0.3188976377952756\n",
      "Epoch: 43 Train Loss: 1.373406132683158, Valid Loss: 1.636015959084034 | Train Acc: 0.44307540660423855, Valid Acc: 0.3228346456692913\n",
      "Epoch: 44 Train Loss: 1.3680302165448666, Valid Loss: 1.6373737081885338 | Train Acc: 0.44553967471660916, Valid Acc: 0.3346456692913386\n",
      "Epoch: 45 Train Loss: 1.3639455754309893, Valid Loss: 1.6356213241815567 | Train Acc: 0.44898965007392805, Valid Acc: 0.3346456692913386\n",
      "Epoch: 46 Train Loss: 1.352217197418213, Valid Loss: 1.6350755095481873 | Train Acc: 0.4603252833908329, Valid Acc: 0.33661417322834647\n",
      "Epoch: 47 Train Loss: 1.350608043372631, Valid Loss: 1.6388254165649414 | Train Acc: 0.4632824051256777, Valid Acc: 0.34448818897637795\n",
      "Epoch: 48 Train Loss: 1.353165427222848, Valid Loss: 1.661627858877182 | Train Acc: 0.46278955150320356, Valid Acc: 0.3248031496062992\n",
      "Epoch: 49 Train Loss: 1.3411543611437082, Valid Loss: 1.6321140825748444 | Train Acc: 0.46673238048299653, Valid Acc: 0.328740157480315\n",
      "Epoch: 50 Train Loss: 1.335003163665533, Valid Loss: 1.6407110467553139 | Train Acc: 0.46426811237062593, Valid Acc: 0.32086614173228345\n",
      "FOLD 2\n",
      "Epoch: 1 Train Loss: 4.031362641602755, Valid Loss: 3.949562296271324 | Train Acc: 0.03794972893050764, Valid Acc: 0.03346456692913386\n",
      "Epoch: 2 Train Loss: 3.435034077614546, Valid Loss: 2.623070701956749 | Train Acc: 0.19862000985707245, Valid Acc: 0.23818897637795275\n",
      "Epoch: 3 Train Loss: 2.082790818065405, Valid Loss: 1.856639452278614 | Train Acc: 0.2572695909314933, Valid Acc: 0.2933070866141732\n",
      "Epoch: 4 Train Loss: 1.7741608023643494, Valid Loss: 1.769236572086811 | Train Acc: 0.2907836372597339, Valid Acc: 0.2677165354330709\n",
      "Epoch: 5 Train Loss: 1.7031116504222155, Valid Loss: 1.7274167761206627 | Train Acc: 0.299162148841794, Valid Acc: 0.25984251968503935\n",
      "Epoch: 6 Train Loss: 1.6704353038221598, Valid Loss: 1.7229403629899025 | Train Acc: 0.30606209955643177, Valid Acc: 0.2618110236220472\n",
      "Epoch: 7 Train Loss: 1.6437121164053679, Valid Loss: 1.7086808532476425 | Train Acc: 0.3164120256283884, Valid Acc: 0.2677165354330709\n",
      "Epoch: 8 Train Loss: 1.6248171515762806, Valid Loss: 1.6546455919742584 | Train Acc: 0.31936914736323313, Valid Acc: 0.3188976377952756\n",
      "Epoch: 9 Train Loss: 1.603762486949563, Valid Loss: 1.6519396156072617 | Train Acc: 0.33169048792508626, Valid Acc: 0.30118110236220474\n",
      "Epoch: 10 Train Loss: 1.58440475538373, Valid Loss: 1.6637898907065392 | Train Acc: 0.33316904879250864, Valid Acc: 0.30708661417322836\n",
      "Epoch: 11 Train Loss: 1.5700934398919344, Valid Loss: 1.6420983597636223 | Train Acc: 0.3484475110892065, Valid Acc: 0.2854330708661417\n",
      "Epoch: 12 Train Loss: 1.5519370511174202, Valid Loss: 1.6693119183182716 | Train Acc: 0.34351897486446525, Valid Acc: 0.297244094488189\n",
      "Epoch: 13 Train Loss: 1.54022185690701, Valid Loss: 1.657041035592556 | Train Acc: 0.36323311976343026, Valid Acc: 0.3031496062992126\n",
      "Epoch: 14 Train Loss: 1.5261579118669033, Valid Loss: 1.6243413090705872 | Train Acc: 0.36126170527353374, Valid Acc: 0.31496062992125984\n",
      "Epoch: 15 Train Loss: 1.5191048737615347, Valid Loss: 1.6102352738380432 | Train Acc: 0.3637259733859044, Valid Acc: 0.3188976377952756\n",
      "Epoch: 16 Train Loss: 1.5136803165078163, Valid Loss: 1.633433222770691 | Train Acc: 0.38048299655002465, Valid Acc: 0.3031496062992126\n",
      "Epoch: 17 Train Loss: 1.5075420290231705, Valid Loss: 1.6404949948191643 | Train Acc: 0.3652045342533268, Valid Acc: 0.3051181102362205\n",
      "Epoch: 18 Train Loss: 1.4923067670315504, Valid Loss: 1.6113134771585464 | Train Acc: 0.3849186791522918, Valid Acc: 0.33661417322834647\n",
      "Epoch: 19 Train Loss: 1.4866339582949877, Valid Loss: 1.6226312443614006 | Train Acc: 0.38590438639724, Valid Acc: 0.3188976377952756\n",
      "Epoch: 20 Train Loss: 1.472101766616106, Valid Loss: 1.6400566399097443 | Train Acc: 0.3868900936421883, Valid Acc: 0.32086614173228345\n",
      "Epoch: 21 Train Loss: 1.462280847132206, Valid Loss: 1.5933670923113823 | Train Acc: 0.3873829472646624, Valid Acc: 0.35039370078740156\n",
      "Epoch: 22 Train Loss: 1.4577185772359371, Valid Loss: 1.6117051467299461 | Train Acc: 0.3932971907343519, Valid Acc: 0.31496062992125984\n",
      "Epoch: 23 Train Loss: 1.4543039873242378, Valid Loss: 1.6048879846930504 | Train Acc: 0.4021685559388862, Valid Acc: 0.3425196850393701\n",
      "Epoch: 24 Train Loss: 1.4407679922878742, Valid Loss: 1.6064676716923714 | Train Acc: 0.41005421389847213, Valid Acc: 0.328740157480315\n",
      "Epoch: 25 Train Loss: 1.442184193059802, Valid Loss: 1.6364042162895203 | Train Acc: 0.3992114342040414, Valid Acc: 0.3248031496062992\n",
      "Epoch: 26 Train Loss: 1.4386591594666243, Valid Loss: 1.6024796068668365 | Train Acc: 0.41005421389847213, Valid Acc: 0.328740157480315\n",
      "Epoch: 27 Train Loss: 1.4241046831011772, Valid Loss: 1.6216508597135544 | Train Acc: 0.41991128634795466, Valid Acc: 0.33070866141732286\n",
      "Epoch: 28 Train Loss: 1.4197657126933336, Valid Loss: 1.6297258511185646 | Train Acc: 0.4070970921636274, Valid Acc: 0.3188976377952756\n",
      "Epoch: 29 Train Loss: 1.4155055843293667, Valid Loss: 1.6450579166412354 | Train Acc: 0.43173977328733365, Valid Acc: 0.33661417322834647\n",
      "Epoch: 30 Train Loss: 1.408419655635953, Valid Loss: 1.6045649200677872 | Train Acc: 0.42927550517496305, Valid Acc: 0.33661417322834647\n",
      "Epoch: 31 Train Loss: 1.401908839121461, Valid Loss: 1.620479516685009 | Train Acc: 0.4208969935929029, Valid Acc: 0.33070866141732286\n",
      "Epoch: 32 Train Loss: 1.399152472615242, Valid Loss: 1.622399628162384 | Train Acc: 0.43518974864465254, Valid Acc: 0.3346456692913386\n",
      "Epoch: 33 Train Loss: 1.3906784933060408, Valid Loss: 1.6198896989226341 | Train Acc: 0.4415968457368162, Valid Acc: 0.32086614173228345\n",
      "Epoch: 34 Train Loss: 1.389509616419673, Valid Loss: 1.6065983772277832 | Train Acc: 0.4322326269098078, Valid Acc: 0.33858267716535434\n",
      "Epoch: 35 Train Loss: 1.3853434827178717, Valid Loss: 1.6195821464061737 | Train Acc: 0.4440611138491868, Valid Acc: 0.33267716535433073\n",
      "Epoch: 36 Train Loss: 1.381199013441801, Valid Loss: 1.6167043074965477 | Train Acc: 0.43518974864465254, Valid Acc: 0.33070866141732286\n",
      "Epoch: 37 Train Loss: 1.36547876521945, Valid Loss: 1.6003697216510773 | Train Acc: 0.4484967964514539, Valid Acc: 0.34448818897637795\n",
      "Epoch: 38 Train Loss: 1.371140155941248, Valid Loss: 1.6426431834697723 | Train Acc: 0.44898965007392805, Valid Acc: 0.33661417322834647\n",
      "Epoch: 39 Train Loss: 1.3655789773911238, Valid Loss: 1.613586038351059 | Train Acc: 0.4475110892065057, Valid Acc: 0.3346456692913386\n",
      "Epoch: 40 Train Loss: 1.354256372898817, Valid Loss: 1.6166831254959106 | Train Acc: 0.4499753573188763, Valid Acc: 0.3464566929133858\n",
      "Epoch: 41 Train Loss: 1.3514158744364977, Valid Loss: 1.6102883890271187 | Train Acc: 0.4539181862986693, Valid Acc: 0.3405511811023622\n",
      "Epoch: 42 Train Loss: 1.343864431604743, Valid Loss: 1.6207288578152657 | Train Acc: 0.4563824544110399, Valid Acc: 0.33858267716535434\n",
      "Epoch: 43 Train Loss: 1.3404866624623537, Valid Loss: 1.6006946340203285 | Train Acc: 0.45490389354361754, Valid Acc: 0.3543307086614173\n",
      "Epoch: 44 Train Loss: 1.3362214230000973, Valid Loss: 1.63710867613554 | Train Acc: 0.4613109906357812, Valid Acc: 0.33267716535433073\n",
      "Epoch: 45 Train Loss: 1.3428027108311653, Valid Loss: 1.6239375472068787 | Train Acc: 0.45243962543124694, Valid Acc: 0.3562992125984252\n",
      "Epoch: 46 Train Loss: 1.3254808187484741, Valid Loss: 1.6290369629859924 | Train Acc: 0.4716609167077378, Valid Acc: 0.34448818897637795\n",
      "Epoch: 47 Train Loss: 1.3273791745305061, Valid Loss: 1.6156517043709755 | Train Acc: 0.4657466732380483, Valid Acc: 0.35826771653543305\n",
      "Epoch: 48 Train Loss: 1.3225422725081444, Valid Loss: 1.6277855411171913 | Train Acc: 0.46278955150320356, Valid Acc: 0.33661417322834647\n",
      "Epoch: 49 Train Loss: 1.3162985108792782, Valid Loss: 1.6296202689409256 | Train Acc: 0.47067520946278957, Valid Acc: 0.35826771653543305\n",
      "Epoch: 50 Train Loss: 1.3190546594560146, Valid Loss: 1.6482002437114716 | Train Acc: 0.45933957614588466, Valid Acc: 0.328740157480315\n",
      "FOLD 3\n",
      "Epoch: 1 Train Loss: 4.102844651788473, Valid Loss: 3.979769602417946 | Train Acc: 0.06059113300492611, Valid Acc: 0.07100591715976332\n",
      "Epoch: 2 Train Loss: 3.415125235915184, Valid Loss: 2.486893206834793 | Train Acc: 0.21822660098522167, Valid Acc: 0.2564102564102564\n",
      "Epoch: 3 Train Loss: 2.036659264937043, Valid Loss: 1.812342643737793 | Train Acc: 0.2704433497536946, Valid Acc: 0.2781065088757396\n",
      "Epoch: 4 Train Loss: 1.7979041785001755, Valid Loss: 1.7445893362164497 | Train Acc: 0.2812807881773399, Valid Acc: 0.27218934911242604\n",
      "Epoch: 5 Train Loss: 1.7468470800668001, Valid Loss: 1.7209540084004402 | Train Acc: 0.29014778325123153, Valid Acc: 0.2682445759368836\n",
      "Epoch: 6 Train Loss: 1.7238392643630505, Valid Loss: 1.700342833995819 | Train Acc: 0.3, Valid Acc: 0.2781065088757396\n",
      "Epoch: 7 Train Loss: 1.7060087472200394, Valid Loss: 1.6913234069943428 | Train Acc: 0.3024630541871921, Valid Acc: 0.28402366863905326\n",
      "Epoch: 8 Train Loss: 1.6857123877853155, Valid Loss: 1.6792202442884445 | Train Acc: 0.30640394088669953, Valid Acc: 0.29191321499013806\n",
      "Epoch: 9 Train Loss: 1.6724763084203005, Valid Loss: 1.66276765614748 | Train Acc: 0.31724137931034485, Valid Acc: 0.27416173570019725\n",
      "Epoch: 10 Train Loss: 1.6554442588239908, Valid Loss: 1.650657020509243 | Train Acc: 0.3251231527093596, Valid Acc: 0.2583826429980276\n",
      "Epoch: 11 Train Loss: 1.6367855835705996, Valid Loss: 1.6451217234134674 | Train Acc: 0.3246305418719212, Valid Acc: 0.2859960552268245\n",
      "Epoch: 12 Train Loss: 1.6270884685218334, Valid Loss: 1.6400495991110802 | Train Acc: 0.3374384236453202, Valid Acc: 0.2938856015779093\n",
      "Epoch: 13 Train Loss: 1.6185952350497246, Valid Loss: 1.6273827478289604 | Train Acc: 0.33251231527093594, Valid Acc: 0.2781065088757396\n",
      "Epoch: 14 Train Loss: 1.600172696635127, Valid Loss: 1.6253786757588387 | Train Acc: 0.34926108374384235, Valid Acc: 0.28994082840236685\n",
      "Epoch: 15 Train Loss: 1.5861211977899075, Valid Loss: 1.617024451494217 | Train Acc: 0.3413793103448276, Valid Acc: 0.28205128205128205\n",
      "Epoch: 16 Train Loss: 1.583769427612424, Valid Loss: 1.612646907567978 | Train Acc: 0.3620689655172414, Valid Acc: 0.28205128205128205\n",
      "Epoch: 17 Train Loss: 1.567396717146039, Valid Loss: 1.6006848067045212 | Train Acc: 0.35763546798029555, Valid Acc: 0.2879684418145957\n",
      "Epoch: 18 Train Loss: 1.5569262318313122, Valid Loss: 1.5959916338324547 | Train Acc: 0.361576354679803, Valid Acc: 0.2879684418145957\n",
      "Epoch: 19 Train Loss: 1.548295309767127, Valid Loss: 1.5868166536092758 | Train Acc: 0.37192118226600984, Valid Acc: 0.28205128205128205\n",
      "Epoch: 20 Train Loss: 1.5426792930811644, Valid Loss: 1.6039210110902786 | Train Acc: 0.3645320197044335, Valid Acc: 0.2958579881656805\n",
      "Epoch: 21 Train Loss: 1.5425167940557003, Valid Loss: 1.587586797773838 | Train Acc: 0.36305418719211824, Valid Acc: 0.30177514792899407\n",
      "Epoch: 22 Train Loss: 1.5307729560881853, Valid Loss: 1.5857411101460457 | Train Acc: 0.3733990147783251, Valid Acc: 0.3116370808678501\n",
      "Epoch: 23 Train Loss: 1.5245850943028927, Valid Loss: 1.586675301194191 | Train Acc: 0.3817733990147783, Valid Acc: 0.3155818540433925\n",
      "Epoch: 24 Train Loss: 1.516443284228444, Valid Loss: 1.5955910608172417 | Train Acc: 0.3807881773399015, Valid Acc: 0.3175542406311637\n",
      "Epoch: 25 Train Loss: 1.5111776869744062, Valid Loss: 1.5884184464812279 | Train Acc: 0.38226600985221676, Valid Acc: 0.3057199211045365\n",
      "Epoch: 26 Train Loss: 1.5055313799530268, Valid Loss: 1.56720769405365 | Train Acc: 0.39064039408866996, Valid Acc: 0.32741617357001973\n",
      "Epoch: 27 Train Loss: 1.4981704447418451, Valid Loss: 1.5636480525135994 | Train Acc: 0.39064039408866996, Valid Acc: 0.3175542406311637\n",
      "Epoch: 28 Train Loss: 1.4914176538586617, Valid Loss: 1.568085178732872 | Train Acc: 0.4004926108374384, Valid Acc: 0.3155818540433925\n",
      "Epoch: 29 Train Loss: 1.4894772339612246, Valid Loss: 1.5619855895638466 | Train Acc: 0.38866995073891625, Valid Acc: 0.3136094674556213\n",
      "Epoch: 30 Train Loss: 1.4876804184168577, Valid Loss: 1.5779450312256813 | Train Acc: 0.39064039408866996, Valid Acc: 0.3116370808678501\n",
      "Epoch: 31 Train Loss: 1.4775782879441977, Valid Loss: 1.5706430673599243 | Train Acc: 0.40492610837438425, Valid Acc: 0.3214990138067061\n",
      "Epoch: 32 Train Loss: 1.4755346849560738, Valid Loss: 1.5662005245685577 | Train Acc: 0.40344827586206894, Valid Acc: 0.3234714003944773\n",
      "Epoch: 33 Train Loss: 1.4658707287162542, Valid Loss: 1.5893481746315956 | Train Acc: 0.40788177339901477, Valid Acc: 0.3096646942800789\n",
      "Epoch: 34 Train Loss: 1.4609825164079666, Valid Loss: 1.5602564811706543 | Train Acc: 0.40295566502463054, Valid Acc: 0.29980276134122286\n",
      "Epoch: 35 Train Loss: 1.4543175175786018, Valid Loss: 1.5648343563079834 | Train Acc: 0.40541871921182265, Valid Acc: 0.33136094674556216\n",
      "Epoch: 36 Train Loss: 1.45007492788136, Valid Loss: 1.5576840564608574 | Train Acc: 0.41330049261083746, Valid Acc: 0.3214990138067061\n",
      "Epoch: 37 Train Loss: 1.444462239742279, Valid Loss: 1.5629500970244408 | Train Acc: 0.4236453201970443, Valid Acc: 0.3175542406311637\n",
      "Epoch: 38 Train Loss: 1.4452439527958632, Valid Loss: 1.566758781671524 | Train Acc: 0.41724137931034483, Valid Acc: 0.3234714003944773\n",
      "Epoch: 39 Train Loss: 1.437172431498766, Valid Loss: 1.5542379319667816 | Train Acc: 0.41674876847290643, Valid Acc: 0.3037475345167653\n",
      "Epoch: 40 Train Loss: 1.4319568257778883, Valid Loss: 1.5667826607823372 | Train Acc: 0.4211822660098522, Valid Acc: 0.33136094674556216\n",
      "Epoch: 41 Train Loss: 1.4204483032226562, Valid Loss: 1.5735227465629578 | Train Acc: 0.4270935960591133, Valid Acc: 0.3214990138067061\n",
      "Epoch: 42 Train Loss: 1.4220030196011066, Valid Loss: 1.5494368523359299 | Train Acc: 0.42758620689655175, Valid Acc: 0.34122287968441817\n",
      "Epoch: 43 Train Loss: 1.416462566703558, Valid Loss: 1.5655977502465248 | Train Acc: 0.42266009852216746, Valid Acc: 0.33530571992110453\n",
      "Epoch: 44 Train Loss: 1.4131369069218636, Valid Loss: 1.560176745057106 | Train Acc: 0.43103448275862066, Valid Acc: 0.3136094674556213\n",
      "Epoch: 45 Train Loss: 1.412114828824997, Valid Loss: 1.5559602305293083 | Train Acc: 0.429064039408867, Valid Acc: 0.32938856015779094\n",
      "Epoch: 46 Train Loss: 1.4031574204564095, Valid Loss: 1.5639368072152138 | Train Acc: 0.4413793103448276, Valid Acc: 0.3333333333333333\n",
      "Epoch: 47 Train Loss: 1.3955775033682585, Valid Loss: 1.5510074570775032 | Train Acc: 0.44482758620689655, Valid Acc: 0.32741617357001973\n",
      "Epoch: 48 Train Loss: 1.3914449401199818, Valid Loss: 1.550032839179039 | Train Acc: 0.44482758620689655, Valid Acc: 0.33530571992110453\n",
      "Epoch: 49 Train Loss: 1.3848044518381357, Valid Loss: 1.5678705498576164 | Train Acc: 0.44778325123152707, Valid Acc: 0.33727810650887574\n",
      "Epoch: 50 Train Loss: 1.3902107905596495, Valid Loss: 1.5549184754490852 | Train Acc: 0.44236453201970444, Valid Acc: 0.33530571992110453\n",
      "FOLD 4\n",
      "Epoch: 1 Train Loss: 3.986425179988146, Valid Loss: 3.9116238057613373 | Train Acc: 0.054679802955665026, Valid Acc: 0.14201183431952663\n",
      "Epoch: 2 Train Loss: 3.553277276456356, Valid Loss: 3.0904224067926407 | Train Acc: 0.17339901477832512, Valid Acc: 0.1893491124260355\n",
      "Epoch: 3 Train Loss: 2.4172001518309116, Valid Loss: 2.0046029165387154 | Train Acc: 0.24433497536945814, Valid Acc: 0.28007889546351084\n",
      "Epoch: 4 Train Loss: 1.8348201345652342, Valid Loss: 1.8231014758348465 | Train Acc: 0.28374384236453204, Valid Acc: 0.2504930966469428\n",
      "Epoch: 5 Train Loss: 1.7523383386433125, Valid Loss: 1.7989311218261719 | Train Acc: 0.2940886699507389, Valid Acc: 0.2702169625246548\n",
      "Epoch: 6 Train Loss: 1.7279372718185186, Valid Loss: 1.794053539633751 | Train Acc: 0.29064039408866993, Valid Acc: 0.27218934911242604\n",
      "Epoch: 7 Train Loss: 1.7096157874912024, Valid Loss: 1.776319794356823 | Train Acc: 0.296551724137931, Valid Acc: 0.2504930966469428\n",
      "Epoch: 8 Train Loss: 1.6912080701440573, Valid Loss: 1.7633123323321342 | Train Acc: 0.31527093596059114, Valid Acc: 0.28007889546351084\n",
      "Epoch: 9 Train Loss: 1.6700067985802889, Valid Loss: 1.7516047060489655 | Train Acc: 0.30935960591133005, Valid Acc: 0.27218934911242604\n",
      "Epoch: 10 Train Loss: 1.661085369065404, Valid Loss: 1.7439490780234337 | Train Acc: 0.3049261083743842, Valid Acc: 0.28205128205128205\n",
      "Epoch: 11 Train Loss: 1.6455895360559225, Valid Loss: 1.726980909705162 | Train Acc: 0.30985221674876845, Valid Acc: 0.29191321499013806\n",
      "Epoch: 12 Train Loss: 1.6331706866621971, Valid Loss: 1.7135834023356438 | Train Acc: 0.3246305418719212, Valid Acc: 0.2781065088757396\n",
      "Epoch: 13 Train Loss: 1.6128467842936516, Valid Loss: 1.7107918933033943 | Train Acc: 0.3270935960591133, Valid Acc: 0.31952662721893493\n",
      "Epoch: 14 Train Loss: 1.6011227257549763, Valid Loss: 1.6962665095925331 | Train Acc: 0.34285714285714286, Valid Acc: 0.30177514792899407\n",
      "Epoch: 15 Train Loss: 1.5916717797517776, Valid Loss: 1.6957600936293602 | Train Acc: 0.3413793103448276, Valid Acc: 0.2859960552268245\n",
      "Epoch: 16 Train Loss: 1.5771351978182793, Valid Loss: 1.6994459480047226 | Train Acc: 0.3369458128078818, Valid Acc: 0.29191321499013806\n",
      "Epoch: 17 Train Loss: 1.565346870571375, Valid Loss: 1.6847242042422295 | Train Acc: 0.35960591133004927, Valid Acc: 0.3037475345167653\n",
      "Epoch: 18 Train Loss: 1.553375357761979, Valid Loss: 1.6754406094551086 | Train Acc: 0.34088669950738915, Valid Acc: 0.3037475345167653\n",
      "Epoch: 19 Train Loss: 1.547393774613738, Valid Loss: 1.6703850850462914 | Train Acc: 0.35960591133004927, Valid Acc: 0.2938856015779093\n",
      "Epoch: 20 Train Loss: 1.5408281832933426, Valid Loss: 1.6731880754232407 | Train Acc: 0.3527093596059113, Valid Acc: 0.30177514792899407\n",
      "Epoch: 21 Train Loss: 1.527472861111164, Valid Loss: 1.6742259189486504 | Train Acc: 0.3541871921182266, Valid Acc: 0.29980276134122286\n",
      "Epoch: 22 Train Loss: 1.51870733872056, Valid Loss: 1.6601766049861908 | Train Acc: 0.3527093596059113, Valid Acc: 0.2938856015779093\n",
      "Epoch: 23 Train Loss: 1.506765078753233, Valid Loss: 1.6616840362548828 | Train Acc: 0.36600985221674875, Valid Acc: 0.30177514792899407\n",
      "Epoch: 24 Train Loss: 1.5007001180201769, Valid Loss: 1.6783577427268028 | Train Acc: 0.3699507389162562, Valid Acc: 0.29980276134122286\n",
      "Epoch: 25 Train Loss: 1.4935957454144955, Valid Loss: 1.6671054437756538 | Train Acc: 0.3699507389162562, Valid Acc: 0.29980276134122286\n",
      "Epoch: 26 Train Loss: 1.4849782194942236, Valid Loss: 1.6700760945677757 | Train Acc: 0.3807881773399015, Valid Acc: 0.3037475345167653\n",
      "Epoch: 27 Train Loss: 1.4781053233891726, Valid Loss: 1.6714118123054504 | Train Acc: 0.3768472906403941, Valid Acc: 0.3037475345167653\n",
      "Epoch: 28 Train Loss: 1.468215562403202, Valid Loss: 1.6630327254533768 | Train Acc: 0.3788177339901478, Valid Acc: 0.30177514792899407\n",
      "Epoch: 29 Train Loss: 1.4609936326742172, Valid Loss: 1.6653350964188576 | Train Acc: 0.39704433497536945, Valid Acc: 0.3057199211045365\n",
      "Epoch: 30 Train Loss: 1.459984265267849, Valid Loss: 1.666989155113697 | Train Acc: 0.3812807881773399, Valid Acc: 0.2938856015779093\n",
      "Epoch: 31 Train Loss: 1.4463382810354233, Valid Loss: 1.676564060151577 | Train Acc: 0.38866995073891625, Valid Acc: 0.3057199211045365\n",
      "Epoch: 32 Train Loss: 1.4452758524566889, Valid Loss: 1.6695158183574677 | Train Acc: 0.38226600985221676, Valid Acc: 0.3037475345167653\n",
      "Epoch: 33 Train Loss: 1.4323915038257837, Valid Loss: 1.6642866879701614 | Train Acc: 0.39507389162561574, Valid Acc: 0.28994082840236685\n",
      "Epoch: 34 Train Loss: 1.4273882936686277, Valid Loss: 1.674344040453434 | Train Acc: 0.4068965517241379, Valid Acc: 0.32938856015779094\n",
      "Epoch: 35 Train Loss: 1.4241434428840876, Valid Loss: 1.6768883913755417 | Train Acc: 0.4019704433497537, Valid Acc: 0.3057199211045365\n",
      "Epoch: 36 Train Loss: 1.4176628682762384, Valid Loss: 1.6742315292358398 | Train Acc: 0.4009852216748768, Valid Acc: 0.27613412228796846\n",
      "Epoch: 37 Train Loss: 1.4039429239928722, Valid Loss: 1.6693422123789787 | Train Acc: 0.41182266009852214, Valid Acc: 0.3037475345167653\n",
      "Epoch: 38 Train Loss: 1.4008134827017784, Valid Loss: 1.672124370932579 | Train Acc: 0.4083743842364532, Valid Acc: 0.3136094674556213\n",
      "Epoch: 39 Train Loss: 1.394765803590417, Valid Loss: 1.6788684576749802 | Train Acc: 0.41674876847290643, Valid Acc: 0.31952662721893493\n",
      "Epoch: 40 Train Loss: 1.3919024523347616, Valid Loss: 1.6816182509064674 | Train Acc: 0.42167487684729066, Valid Acc: 0.3057199211045365\n",
      "Epoch: 41 Train Loss: 1.3866056688129902, Valid Loss: 1.6857172846794128 | Train Acc: 0.4241379310344828, Valid Acc: 0.29980276134122286\n",
      "Epoch: 42 Train Loss: 1.3791952636092901, Valid Loss: 1.6794483214616776 | Train Acc: 0.41773399014778323, Valid Acc: 0.29980276134122286\n",
      "Epoch: 43 Train Loss: 1.3734533581882715, Valid Loss: 1.6932839825749397 | Train Acc: 0.41970443349753694, Valid Acc: 0.3096646942800789\n",
      "Epoch: 44 Train Loss: 1.367081081494689, Valid Loss: 1.6968257278203964 | Train Acc: 0.4246305418719212, Valid Acc: 0.3155818540433925\n",
      "Epoch: 45 Train Loss: 1.3629813361912966, Valid Loss: 1.7050769478082657 | Train Acc: 0.4241379310344828, Valid Acc: 0.3175542406311637\n",
      "Epoch: 46 Train Loss: 1.3537946660071611, Valid Loss: 1.7049480453133583 | Train Acc: 0.43645320197044335, Valid Acc: 0.3037475345167653\n",
      "Epoch: 47 Train Loss: 1.3485867138952017, Valid Loss: 1.711417779326439 | Train Acc: 0.4236453201970443, Valid Acc: 0.3234714003944773\n",
      "Epoch: 48 Train Loss: 1.3476542457938194, Valid Loss: 1.6986910179257393 | Train Acc: 0.4295566502463054, Valid Acc: 0.3076923076923077\n",
      "Epoch: 49 Train Loss: 1.3381460886448622, Valid Loss: 1.6996471732854843 | Train Acc: 0.44236453201970444, Valid Acc: 0.2958579881656805\n",
      "Epoch: 50 Train Loss: 1.330918712541461, Valid Loss: 1.7027327567338943 | Train Acc: 0.43645320197044335, Valid Acc: 0.3076923076923077\n",
      "FOLD 5\n",
      "Epoch: 1 Train Loss: 3.8921667374670506, Valid Loss: 3.9334269016981125 | Train Acc: 0.08522167487684729, Valid Acc: 0.08678500986193294\n",
      "Epoch: 2 Train Loss: 3.43337569385767, Valid Loss: 2.7532974034547806 | Train Acc: 0.13694581280788176, Valid Acc: 0.1301775147928994\n",
      "Epoch: 3 Train Loss: 2.2182142678648233, Valid Loss: 1.9736082330346107 | Train Acc: 0.2334975369458128, Valid Acc: 0.2702169625246548\n",
      "Epoch: 4 Train Loss: 1.8175513818860054, Valid Loss: 1.7951161563396454 | Train Acc: 0.28620689655172415, Valid Acc: 0.28402366863905326\n",
      "Epoch: 5 Train Loss: 1.7377216592431068, Valid Loss: 1.761929728090763 | Train Acc: 0.29211822660098524, Valid Acc: 0.28205128205128205\n",
      "Epoch: 6 Train Loss: 1.7049348074942827, Valid Loss: 1.7191875576972961 | Train Acc: 0.3054187192118227, Valid Acc: 0.2682445759368836\n",
      "Epoch: 7 Train Loss: 1.6799470949918032, Valid Loss: 1.720518596470356 | Train Acc: 0.3137931034482759, Valid Acc: 0.28994082840236685\n",
      "Epoch: 8 Train Loss: 1.6672585774213076, Valid Loss: 1.6829559952020645 | Train Acc: 0.30985221674876845, Valid Acc: 0.2682445759368836\n",
      "Epoch: 9 Train Loss: 1.6461014468222857, Valid Loss: 1.696680799126625 | Train Acc: 0.3305418719211823, Valid Acc: 0.3116370808678501\n",
      "Epoch: 10 Train Loss: 1.6274928506463766, Valid Loss: 1.6790739595890045 | Train Acc: 0.32660098522167486, Valid Acc: 0.2583826429980276\n",
      "Epoch: 11 Train Loss: 1.6144178826361895, Valid Loss: 1.6669219359755516 | Train Acc: 0.3394088669950739, Valid Acc: 0.2781065088757396\n",
      "Epoch: 12 Train Loss: 1.5988740716129541, Valid Loss: 1.6645379140973091 | Train Acc: 0.3438423645320197, Valid Acc: 0.2938856015779093\n",
      "Epoch: 13 Train Loss: 1.5933613814413548, Valid Loss: 1.6459491401910782 | Train Acc: 0.3482758620689655, Valid Acc: 0.3057199211045365\n",
      "Epoch: 14 Train Loss: 1.5818203296512365, Valid Loss: 1.633256085216999 | Train Acc: 0.3394088669950739, Valid Acc: 0.27218934911242604\n",
      "Epoch: 15 Train Loss: 1.5626658890396357, Valid Loss: 1.6303754523396492 | Train Acc: 0.35714285714285715, Valid Acc: 0.3037475345167653\n",
      "Epoch: 16 Train Loss: 1.5580179151147604, Valid Loss: 1.6338169425725937 | Train Acc: 0.3610837438423645, Valid Acc: 0.2879684418145957\n",
      "Epoch: 17 Train Loss: 1.5451776683330536, Valid Loss: 1.6204311698675156 | Train Acc: 0.36600985221674875, Valid Acc: 0.3155818540433925\n",
      "Epoch: 18 Train Loss: 1.537310928106308, Valid Loss: 1.6411407515406609 | Train Acc: 0.3665024630541872, Valid Acc: 0.28402366863905326\n",
      "Epoch: 19 Train Loss: 1.5346052516251802, Valid Loss: 1.6252485439181328 | Train Acc: 0.36798029556650247, Valid Acc: 0.3037475345167653\n",
      "Epoch: 20 Train Loss: 1.5302782822400331, Valid Loss: 1.6192757189273834 | Train Acc: 0.3665024630541872, Valid Acc: 0.3214990138067061\n",
      "Epoch: 21 Train Loss: 1.5170514974743128, Valid Loss: 1.6296406462788582 | Train Acc: 0.3812807881773399, Valid Acc: 0.3057199211045365\n",
      "Epoch: 22 Train Loss: 1.5153708662837744, Valid Loss: 1.5998683497309685 | Train Acc: 0.3793103448275862, Valid Acc: 0.3214990138067061\n",
      "Epoch: 23 Train Loss: 1.5059095956385136, Valid Loss: 1.632687285542488 | Train Acc: 0.37733990147783253, Valid Acc: 0.2879684418145957\n",
      "Epoch: 24 Train Loss: 1.4977911673486233, Valid Loss: 1.6292796209454536 | Train Acc: 0.38620689655172413, Valid Acc: 0.3155818540433925\n",
      "Epoch: 25 Train Loss: 1.4989985916763544, Valid Loss: 1.6194944828748703 | Train Acc: 0.3832512315270936, Valid Acc: 0.3037475345167653\n",
      "Epoch: 26 Train Loss: 1.4868556894361973, Valid Loss: 1.6342997699975967 | Train Acc: 0.4039408866995074, Valid Acc: 0.2879684418145957\n",
      "Epoch: 27 Train Loss: 1.4846061021089554, Valid Loss: 1.6302310153841972 | Train Acc: 0.3768472906403941, Valid Acc: 0.2781065088757396\n",
      "Epoch: 28 Train Loss: 1.4754434898495674, Valid Loss: 1.6208297535777092 | Train Acc: 0.39655172413793105, Valid Acc: 0.2978303747534517\n",
      "Epoch: 29 Train Loss: 1.4707098677754402, Valid Loss: 1.6318639069795609 | Train Acc: 0.39901477832512317, Valid Acc: 0.2879684418145957\n",
      "Epoch: 30 Train Loss: 1.4608304128050804, Valid Loss: 1.6098283156752586 | Train Acc: 0.4044334975369458, Valid Acc: 0.2859960552268245\n",
      "Epoch: 31 Train Loss: 1.458023589104414, Valid Loss: 1.6127507835626602 | Train Acc: 0.39655172413793105, Valid Acc: 0.28994082840236685\n",
      "Epoch: 32 Train Loss: 1.451577426865697, Valid Loss: 1.6437349244952202 | Train Acc: 0.40788177339901477, Valid Acc: 0.3076923076923077\n",
      "Epoch: 33 Train Loss: 1.4507582429796457, Valid Loss: 1.6241118088364601 | Train Acc: 0.40935960591133, Valid Acc: 0.2958579881656805\n",
      "Epoch: 34 Train Loss: 1.4411931466311216, Valid Loss: 1.6204291060566902 | Train Acc: 0.4088669950738916, Valid Acc: 0.2859960552268245\n",
      "Epoch: 35 Train Loss: 1.437352892011404, Valid Loss: 1.621205486357212 | Train Acc: 0.4083743842364532, Valid Acc: 0.2879684418145957\n",
      "Epoch: 36 Train Loss: 1.436543321236968, Valid Loss: 1.61952543258667 | Train Acc: 0.39655172413793105, Valid Acc: 0.30177514792899407\n",
      "Epoch: 37 Train Loss: 1.4301941320300102, Valid Loss: 1.6209022626280785 | Train Acc: 0.41674876847290643, Valid Acc: 0.3057199211045365\n",
      "Epoch: 38 Train Loss: 1.4241353403776884, Valid Loss: 1.6228148713707924 | Train Acc: 0.42512315270935963, Valid Acc: 0.2879684418145957\n",
      "Epoch: 39 Train Loss: 1.4200347028672695, Valid Loss: 1.6303616017103195 | Train Acc: 0.41773399014778323, Valid Acc: 0.2859960552268245\n",
      "Epoch: 40 Train Loss: 1.418087026104331, Valid Loss: 1.6287032812833786 | Train Acc: 0.41576354679802957, Valid Acc: 0.29980276134122286\n",
      "Epoch: 41 Train Loss: 1.4120678659528494, Valid Loss: 1.627493403851986 | Train Acc: 0.4211822660098522, Valid Acc: 0.27613412228796846\n",
      "Epoch: 42 Train Loss: 1.40597815066576, Valid Loss: 1.6447879746556282 | Train Acc: 0.4231527093596059, Valid Acc: 0.28994082840236685\n",
      "Epoch: 43 Train Loss: 1.4063791409134865, Valid Loss: 1.6252064928412437 | Train Acc: 0.42807881773399015, Valid Acc: 0.29191321499013806\n",
      "Epoch: 44 Train Loss: 1.3938626162707806, Valid Loss: 1.6375401467084885 | Train Acc: 0.4295566502463054, Valid Acc: 0.2938856015779093\n",
      "Epoch: 45 Train Loss: 1.4001402035355568, Valid Loss: 1.6280558034777641 | Train Acc: 0.4152709359605911, Valid Acc: 0.28994082840236685\n",
      "Epoch: 46 Train Loss: 1.388611687347293, Valid Loss: 1.6603125035762787 | Train Acc: 0.4246305418719212, Valid Acc: 0.27613412228796846\n",
      "Epoch: 47 Train Loss: 1.3887962279841304, Valid Loss: 1.6393724530935287 | Train Acc: 0.4295566502463054, Valid Acc: 0.2859960552268245\n",
      "Epoch: 48 Train Loss: 1.386087628081441, Valid Loss: 1.6391427516937256 | Train Acc: 0.4320197044334975, Valid Acc: 0.28994082840236685\n",
      "Epoch: 49 Train Loss: 1.375538680702448, Valid Loss: 1.6317301392555237 | Train Acc: 0.44778325123152707, Valid Acc: 0.29980276134122286\n",
      "Epoch: 50 Train Loss: 1.3742696419358253, Valid Loss: 1.646746464073658 | Train Acc: 0.4458128078817734, Valid Acc: 0.2879684418145957\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, loss_fn, train_sampler_size): \n",
    "    \"\"\"\n",
    "    Trains the model for one epoch and returns the average training loss and accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    running_loss = 0.  \n",
    "    running_correct = 0.\n",
    "\n",
    "    # Looping through all samples in a batch\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Extracting the board tensor\n",
    "        inputs = data[0]\n",
    "        # Extracting the tile of the piece to move\n",
    "        labels = data[1][:, 0]\n",
    "        \n",
    "        # Moving inputs and labels to the gpu/cpu\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Resetting the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Calculating model's output\n",
    "        outputs = model(inputs)\n",
    "        # Calculating the sample loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Calculating the gradient\n",
    "        loss.backward()\n",
    "        # Updating model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Adding the last loss to the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate number of correct predictions\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    # Averaging the loss for all samples in the batch\n",
    "    running_loss /= (i + 1)\n",
    "\n",
    "    # Calculate accuracy based on the total samples in the fold (train_sampler_size)\n",
    "    train_accuracy = running_correct / train_sampler_size\n",
    "\n",
    "    return running_loss, train_accuracy\n",
    "\n",
    "\n",
    "def validation_epoch(model, validation_loader, loss_fn, val_sampler_size):\n",
    "    \"\"\"\n",
    "    Validates the model for one epoch and returns the average validation loss and accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    running_vloss = 0.\n",
    "    running_vcorrect = 0.\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculations for validation set\n",
    "    with torch.no_grad():\n",
    "        # Looping through all batches in the validation set\n",
    "        for i, v_data in enumerate(validation_loader):\n",
    "            # Getting the tensors of the validation data\n",
    "            vinputs = v_data[0]\n",
    "            vlabels = v_data[1][:, 0]\n",
    "\n",
    "            # Moving inputs and labels to the gpu/cpu\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "\n",
    "            # Calculating the output of the model\n",
    "            voutputs = model(vinputs)\n",
    "            # Calculating the loss of the model in the validation sample\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            # Adding this sample's loss to the total loss\n",
    "            running_vloss += vloss.item()\n",
    "\n",
    "            # Calculate number of correct predictions\n",
    "            _, predictions = torch.max(voutputs.data, 1)\n",
    "            running_vcorrect += (predictions == vlabels).sum().item()\n",
    "\n",
    "    # Averaging the loss for all samples in the validation set\n",
    "    running_vloss /= (i + 1)\n",
    "\n",
    "    # Calculate accuracy based on the total samples in the fold (val_sampler_size)\n",
    "    validation_accuracy = running_vcorrect / val_sampler_size\n",
    "\n",
    "    return running_vloss, validation_accuracy\n",
    "\n",
    "\n",
    "def train_multiple_folds(n_epochs, batch_size, splits, writer, loss_fn):\n",
    "\n",
    "    best_vloss = 1_000\n",
    "\n",
    "    epoch_tloss = [0. for _ in range(n_epochs)]\n",
    "    epoch_tacc = [0. for _ in range(n_epochs)]\n",
    "    epoch_vloss = [0. for _ in range(n_epochs)]\n",
    "    epoch_vacc = [0. for _ in range(n_epochs)]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(train_dataset)))):\n",
    "        print(f\"FOLD {fold+1}\")\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "        model = PieceToMoveNet()\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "        train_sampler_size = len(train_sampler)\n",
    "        val_sampler_size = len(val_sampler)\n",
    "\n",
    "        avg_vloss = 0.\n",
    "\n",
    "        for epoch in range(n_epochs): \n",
    "            train_loss, train_correct = train_epoch(model, optimizer, train_loader, loss_fn, train_sampler_size)\n",
    "            val_loss, val_correct = validation_epoch(model, val_loader, loss_fn, val_sampler_size)\n",
    "\n",
    "            epoch_tloss[epoch] += train_loss\n",
    "            epoch_tacc[epoch] += train_correct\n",
    "            epoch_vloss[epoch] += val_loss\n",
    "            epoch_vacc[epoch] += val_correct\n",
    "\n",
    "            avg_vloss += val_loss\n",
    "\n",
    "            print(f\"Epoch: {epoch+1} Train Loss: {train_loss}, Valid Loss: {val_loss} | Train Acc: {train_correct}, Valid Acc: {val_correct}\")\n",
    "\n",
    "        avg_vloss = avg_vloss / (epoch + 1)\n",
    "\n",
    "        # Saving the model if the loss on the validation is lower than the best one\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = f\"models/piece_to_move_net_{timestamp}_{fold}\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_tloss[epoch] = epoch_tloss[epoch] / (fold + 1)\n",
    "        epoch_tacc[epoch] = epoch_tacc[epoch] / (fold + 1)\n",
    "        epoch_vloss[epoch] = epoch_vloss[epoch] / (fold + 1)\n",
    "        epoch_vacc[epoch] = epoch_vacc[epoch] / (fold + 1)\n",
    "\n",
    "\n",
    "        # Adding insights\n",
    "        writer.add_scalars(\"Loss\", {\"Training\": epoch_tloss[epoch], \"Validation\": epoch_vloss[epoch]}, epoch + 1)\n",
    "        writer.add_scalars(\"Accuracy\", {\"Training\": epoch_tacc[epoch], \"Validation\": epoch_vacc[epoch]}, epoch + 1)\n",
    "        writer.flush()\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "K = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Logs training statistics for TensorBoard visualization\n",
    "writer = SummaryWriter(f\"runs/piece_to_move_{timestamp}\")  \n",
    "splits = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "train_multiple_folds(EPOCHS, BATCH_SIZE, splits, writer, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(board: chess.Board, outputs: np.arry, labels: np.array) -> np.array:\n",
    "    \"\"\"Creates mask with the position of the pieces that are able to move\"\"\"\n",
    "\n",
    "    mask = np.zeros((8,8)) # 8x8 mask for the chessboard\n",
    "\n",
    "    # Obtaining legal moves from the board\n",
    "    legal_moves = list(board.legal_moves)\n",
    "\n",
    "    # Indicating with 1s the valid squares\n",
    "    for move in legal_moves:\n",
    "        to_square = move.to_square\n",
    "        to_row, to_col = divmod(to_square, 8)\n",
    "        mask[to_row, to_col] = 1 # A valid square\n",
    "\n",
    "    # Reshaping mask to match output and labels\n",
    "    move_mask = mask.flatten() # Converts 8*8 2D array to a 1D array with 64 elements\n",
    "\n",
    "    masked_outputs = outputs * move_mask\n",
    "    masked_labels = labels * move_mask\n",
    "\n",
    "    return masked_outputs, masked_labels\n",
    "\n",
    "def update_board( board: chess.Board, move: chess.Move ) -> chess.Board:\n",
    "    \"\"\"This function is responsible for updating the board everytime a move is made\"\"\"\n",
    "\n",
    "    board.push(move) # Add move to the board\n",
    "    \n",
    "    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS VALIDATION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    \"\"\"Resets the weights of the model, so the model is trained with randomly initalized weights\"\"\"\n",
    "\n",
    "    # List of layers containing reset parameters\n",
    "    layer_types = [nn.Conv2d, nn.Linear, nn.BatchNorm2d]\n",
    "\n",
    "    # Iterating through all layers of the model\n",
    "    for layer in model.modules():\n",
    "        # Check layers with reset parameters\n",
    "        if type(layer) in layer_types:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
