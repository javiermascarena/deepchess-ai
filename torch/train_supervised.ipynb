{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maux_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1\\Documents\\ajedrez\\deepchess-ai\\torch\\aux_functions.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# The layer number of each piece type in the tensor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:764\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m    763\u001b[0m __name, __obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    766\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(__name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "from aux_functions import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "#from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import chess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PROCESSING**\n",
    "\n",
    "- Importing the pgn data\n",
    "- Transforming the data to sparce tensors \n",
    "- Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PERCENT = 0.25\n",
    "\n",
    "# Load pgn paths\n",
    "pgns = import_data(1)\n",
    "\n",
    "# Convert pgns to tensors\n",
    "board_tensors, next_moves = parse_pgn_to_tensors(pgns)\n",
    "\n",
    "# Converting the dataset into a custom pytorch one\n",
    "dataset = ChessDataset(board_tensors, next_moves)\n",
    "\n",
    "# Splitting the data into train and test\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [1-TEST_PERCENT, TEST_PERCENT])\n",
    "\n",
    "print(len(test_data))  # Number of states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK DESIGN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Whether to do the operations on the cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PieceToMoveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Takes as input a tensor of 14 channels (8x8 board)\n",
    "        self.conv1 = nn.Conv2d(14, 6, 3)  # 6 filters, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # Max pooling with 2x2 window\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)  # 16 filters, 3x3 kernel\n",
    "        \n",
    "        # If starting with 8x8, after two pool layers it becomes 2x2.\n",
    "        # Output from conv2 will be (16 channels, 2x2 feature maps), flattened to 16 * 2 * 2 = 64\n",
    "        self.fc1 = nn.Linear(16 * 2 * 2, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Predicts the tile to move the piece from (64 possible tiles on the board)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Apply first conv + pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Apply second conv + pooling\n",
    "        x = torch.flatten(x, BATCH_SIZE)  # Flatten all dimensions except batch size\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer 1\n",
    "        x = F.relu(self.fc2(x))  # Fully connected layer 2\n",
    "        x = self.fc3(x)          # Output layer (no activation, logits for classification)\n",
    "        return x\n",
    "\n",
    "piece_to_move_net = PieceToMoveNet()\n",
    "# Move the network to gpu / cpu befor initializing the optimizer\n",
    "piece_to_move_net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(piece_to_move_net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING LOOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(board: chess.Board, outputs: np.arry, labels: np.array) -> np.array:\n",
    "    \"\"\"Creates mask with legal moves from the current board state\"\"\"\n",
    "\n",
    "    mask = np.zeros((8,8)) # 8x8 mask for the chessboard\n",
    "\n",
    "    # Obtaining legal moves from the board\n",
    "    legal_moves = list(board.legal_moves)\n",
    "\n",
    "    # Indicating with 1s the valid squares\n",
    "    for move in legal_moves:\n",
    "        to_square = move.to_square\n",
    "        to_row, to_col = divmod(to_square, 8)\n",
    "        mask[to_row, to_col] = 1 # A valid square\n",
    "\n",
    "    # Reshaping mask to match output and labels\n",
    "    move_mask = mask.flatten() # Converts 8*8 2D array to a 1D array with 64 elements\n",
    "\n",
    "    masked_outputs = outputs * move_mask\n",
    "    masked_labels = labels * move_mask\n",
    "\n",
    "    return masked_outputs, masked_labels\n",
    "\n",
    "def update_board( board: chess.Board, move: chess.Move ) -> chess.Board:\n",
    "    \"\"\"This function is responsible for updating the board everytime a move is made\"\"\"\n",
    "\n",
    "    board.push(move) # Add move to the board\n",
    "    \n",
    "    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")tiwriter = SummaryWriter(f\"runs/piece_to_move_{timestamp}\")\n",
    "ontrain_data, validation_data = torch.utils.data.random_split(train_data, [1-TEST_PERCENT, TEST_PERCENT])\n",
    "octraining_loader = torch.utils.data.dataLoader(train_data, BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "validation_loader = torch.utils.data.dataLoader(validation_data, BATCH_SIZE, shuffle=True, pin_memory=True)h_index: int, tb_writer): \n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = piece_to_move_net(inputs)\n",
    "\n",
    "               \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999: \n",
    "            last_loss = running_loss / 1000\n",
    "            print(f\" batch {i + 1}, loss: {last_loss}\")\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "    print(f\"EPOCH {epoch    for epoch in range(EPOCHS): \n",
    "        print modelCH {epoch + 1}: \")\n",
    "\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch, writer)\n",
    "\n",
    "        model.train(False)\n",
    "        running_vloss = 0.0\n",
    "        for i, v_data in enumerate(validation_loader):\n",
    "            vinputs = v_data[0]\n",
    "            vlabels = v_data[1]\n",
    "\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print(f\"LOSS train {avg_loss}, valid {avg_vloss}\")\n",
    "\n",
    "        writer.add_scalars(\"Training vs Validation Loss\", {\n",
    "            \"Training\": avg_loss, \"Validation\": avg_vloss}, \n",
    "            epoch + 1)\n",
    "        writer.flush()\n",
    "        \n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_loss\n",
    "            model_path = f\"model_{timestamp}_{epoch}\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        epoch += 1\n",
    "        \n",
    "        train_multimple_epchso(), EPOCHStramopiecepiece_to_move_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS VALIDATION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    \"\"\"Resets the weights of the model, so the model is trained with randomly initalized weights\"\"\"\n",
    "\n",
    "    # List of layers containing reset parameters\n",
    "    layer_types = [nn.Conv2d, nn.Linear, nn.BatchNorm2d]\n",
    "\n",
    "    # Iterating through all layers of the model\n",
    "    for layer in model.modules():\n",
    "        # Check layers with reset parameters\n",
    "        if type(layer) in layer_types:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
